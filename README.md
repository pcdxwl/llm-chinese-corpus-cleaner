# 大模型数据集预处理Pipeline
一个大模型数据集预处理的pipeline，包含从原始数据集到清洗、去重、过滤、质量评估、存储的全流程。
## 功能特性
- 1.基于正则匹配进行数据清洗、修复、归一化。
- 2.基于MinHash和LSH进行数据去重
- 3.数据过滤依据以下三个标准：
    - (1) 文本毒性得分，由 multilingual-toxic-xlm-roberta 模型评估；
    - (2) 语言模型困惑度（Perplexity, PPL），由 GPT-2 计算；
    - (3) 文本字符/词数长度。 
- 4.基于重复率、毒性、PPL和词汇多样性进行质量评估
- 5.自动绘制关键质量指标分布直方图。
- 6.支持按照关键质量指标抽样供人工审核。
## 项目结构
    ├── README.md           
    ├── config.py       # 参数配置
    ├── detail.json     # 处理结果明细
    ├── stats.json      # 处理结果统计
    ├── main.py         # 运行pipeline
    └── utils.py        # 处理过程各模块
## 优化效果示例（真实模拟）
- 以Belle_open_source_0.5M数据集为例
### 数据处理
    原始数据
        ↓	
    [清洗]→正则、分词、归一化——→提升语言质量	
        ↓	
    [去重]→MinHash +LSH——→降低重复率	
        ↓
    [过滤]→毒性检测、PPL 过滤——→降低毒性比例、优化信息熵	
        ↓
    [综合效果]→去除广告/模板——→提升词汇多样性	
        ↓ 
    存储高质量数据集
- 数据集输入进pipeline，经历上述处理流程，过滤不符合要求的数据。

### 质量评估
- 以困惑度PPL检测为例
#### 1. 初始阈值
- 根据经验设置初始过滤阈值，即过滤的上限：PPL=150,毒性=0.5，重复率=0.85
#### 2. 有效性验证
- 2.1 分布特征。
    - 下图为PPL的直方图，呈右偏分布，表明多数样本易于建模，少数样本因异常或复杂性导致困惑度较高。 
    - PPL分布在超过110后呈现显著长尾，反映高困惑样本的集中出现。原阈值150可能过于宽松，应下调至110以截断低质量尾部，提升数据集整体质量。
    ![PPL分布直方图](./PPL_before_pic.png)
- 2.2 人工抽样
    - 阈值附近（PPL=145~155）：
        - 该区域样本主要包括三类：多语言混合、数学计算和语言不通顺。前两类并非低质，可经特殊处理识别并保留；仅第三类应予过滤。
    - 极值：
        - 最小值（0~10）：该区域样本质量高、内容丰富。
        - 最大值（290~300）：该区域样本与阈值附近样本具有类似特征。
    - 峰值（11.97）：
        - 该区域样本与最小值附近样本具有类似特征。
        - 该区域样本无显著特征，且无不利于模型训练的因素。
    - 优化阈值附近（105~115）：
        - 该区域样本特征与初始阈值（150）附近相似，将阈值下调至110可有效过滤长尾中的低质数据。
#### 3. 优化阈值
基于优化后阈值将数据集重新输入pipeline，两次结果对比如下：
| 指标               | 原始数据 | 初始处理（阈值max_ppl=150;max_toxic=0.5） | 二次优化（阈值max_ppl=110;max_toxic=0.8）       |
|--------------------|----------------------|---------------------|------------|
| duplica_ratio(重复率)| 0.0000 | 0.0000 | 0.0000|
| mean_toxic(平均毒性)| 0.2379   | 0.2329 | 0.2378|
| max_toxic(最大毒性)| 0.9060| 0.4999|0.7720|
| min_toxic(最小毒性)| 0.0004 | 0.0004|0.0004|
| mean_ppl(平均困惑度PPL)| 27.4488 | 23.2681|22.4204|
| max_ppl(最大困惑度PPL)| 297.5889 | 148.9859|109.8594|
| min_ppl(最小困惑度PPL)| 2.4653 | 2.4653|2.4653|
| mean_cttr(平均词汇多样性cttr)| 3.7173 | 3.7227|3.8912|
| max_cttr(最大词汇多样性cttr)| 12.2253 | 12.2253|12.3542|
| min_cttr(最小词汇多样性cttr)| 0.0000 | 0.0000|0.8832|
- 优化阈值的评估结果优于初始阈值。
## 运行方式
    python main.py
### 核心函数1 data_pipeline(input_path, output_path,detail_path,stats_path) 
- 包含数据加载+清洗+去重+过滤+存储
- 采用端到端的模型，仅需提供文件保存路径即可。
### 核心函数2 result_check(detail_path,stats_path,input_path) 
- 包含评估报告+分布直方图+漏斗图+按阈值抽样

