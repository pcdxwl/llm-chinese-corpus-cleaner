# 大模型数据集预处理Pipeline
一个大模型数据集预处理的pipeline，用于从原始数据到清洗、去重、过滤、质量评估、存储的全流程自动化。
## 功能特性
- 1.基于正则匹配进行数据清洗、修复、归一化。
- 2.基于MinHash和LSH进行数据去重
- 3.数据过滤依据以下三个标准：(1) 文本毒性得分，由 multilingual-toxic-xlm-roberta 模型评估；(2) 语言模型困惑度（Perplexity, PPL），由 GPT-2 计算；(3) 文本字符/词数长度。 
- 4.基于重复率、毒性、PPL和词汇多样性进行质量评估
- 5.自动绘制关键质量指标分布直方图。
- 6.支持按照关键质量指标抽样供人工审核。
## 项目结构
    ├── README.md           
    ├── config.py       # 参数配置
    ├── detail.json     # 处理结果明细
    ├── stats.json      # 处理结果统计
    ├── main.py         # 运行pipeline
    └── utils.py        # 处理过程各模块
## 优化效果示例（真实模拟）
以Belle_open_source_0.5M数据集为例
### 质量评估
#### 1. 初始阈值
- 初始设置最大阈值，作为过滤的上线：ppl=150,毒性=0.5，重复率=0.85
#### 2. 有效性验证
- 2.1 画出指标分布直方图，观察其分布特征。
    - 下图为PPL的直方图，呈现出典型的右偏分布（Right-skewed / Positive skew）
    - 这说明大多数样本的困惑度较低，但存在少量高困惑度的异常或复杂样本。
    - ppl>110后出现长尾，考虑将ppl阈值下降为110，以便获得更高质量的数据集。
    ![ppl分布直方图](./ppl_before_pic.png)
- 2.2 人工抽样
    - 阈值附近（150）：大于阈值的可分为3类：多语言混合
        - 数学计算和语言不通顺（明显机翻）
        - 抽样检查100~110的数据仍符合上述特征，和150以上的内容差异不明显。
        - 结合ppl分布，在ppl=110时接近长尾的开端，因此阈值设为110
    - min：很通顺，也不会过于简单，无需过滤
    - max：
        - 可分为3类：多语言混合、数学计算和语言不通顺（明显机翻）
    峰值：通顺，无有害特征
#### 3. 优化阈值
按照上述的分析方法，基于优化后阈值对数据集进行二次处理，结果如下：
（todo 统计表格）
| 指标               | 初始处理（阈值=100） | 二次优化（阈值=85） | 提升       |
|--------------------|----------------------|---------------------|------------|
| 数据总量           | 85,000 条            | 92,000 条           | **+8.2%**  |
| 人工抽检合格率     | 92%                  | 93%                 | +1%        |
| 低质样本残留率     | 5%                   | 3%                  | **-40%**   |

## 运行方式
python main.py
### 核心函数1 data_pipeline(input_path, output_path,detail_path,stats_path) 数据加载+清洗+去重+过滤+存储
    采用端到端的模型，仅需提供文件保存路径即可。
    input_path 输入数据保存路径
    output_path 输出结果保存路径
    detail_path  得分明细保存路径
    stats_path  得分统计保存路径
### 核心函数2 result_check(detail_path,stats_path,input_path) — 评估报告+分布图+抽样

